{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcEJRPFmqy5XrI4Txmtm8a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/programmer-ayesha/Orchestration_Agent/blob/main/language_orchestration_agents_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔄 Multi-Agent Orchestration Workflow using OpenAI Agents SDK\n"
      ],
      "metadata": {
        "id": "NuUxTOmn18Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykCnVV9j2jfb",
        "outputId": "b25afcf8-7c8f-42ba-d75f-4d411cef5567"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq \"openai-agents[litellm]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SxeaJw42vMq",
        "outputId": "4869af4c-22a6-45c3-c74a-bda75674e2bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "SNsgtvMT20uY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "LCBo2R-n25fR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model = \"gemini/gemini-2.0-flash\"\n",
        "api_key = gemini_api_key"
      ],
      "metadata": {
        "id": "QGOOoooK2856"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGzLxKcq1pBS",
        "outputId": "313dc85e-df4a-41a2-b5f3-8e17e7a29cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:openai.agents:OPENAI_API_KEY is not set, skipping trace export\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final Output: Hola, ¿cómo estás?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- Setup and Imports ---\n",
        "import asyncio\n",
        "from agents import Agent, Runner\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "\n",
        "# Model & API key (Replace with your own)\n",
        "Model = \"gemini/gemini-2.0-flash\"\n",
        "api_key = gemini_api_key # 🔒 Keep secret\n",
        "\n",
        "# --- Agent: Detect Language ---\n",
        "detect_language_agent = Agent(\n",
        "    name=\"Detect Language Agent\",\n",
        "    instructions=\"You are a language detection expert. Identify the input language of the user's message.\",\n",
        "    model=LitellmModel(model=Model, api_key=api_key),\n",
        ")\n",
        "\n",
        "# --- Agent: Spanish Translator ---\n",
        "spanish_agent = Agent(\n",
        "    name=\"Spanish Agent\",\n",
        "    instructions=\"You translate the user's message to Spanish.\",\n",
        "    model=LitellmModel(model=Model, api_key=api_key),\n",
        ")\n",
        "\n",
        "# --- Agent: French Translator ---\n",
        "french_agent = Agent(\n",
        "    name=\"French Agent\",\n",
        "    instructions=\"You translate the user's message to French.\",\n",
        "    model=LitellmModel(model=Model, api_key=api_key),\n",
        ")\n",
        "\n",
        "# --- Agent: Orchestrator ---\n",
        "# This agent decides what to do based on detected language\n",
        "orchestrator_agent = Agent(\n",
        "    name=\"Orchestrator Agent\",\n",
        "    instructions=(\n",
        "        \"You are a translation orchestrator. First, use the language detection tool \"\n",
        "        \"to find the input language. Then call the appropriate translator tool to translate it to English. \"\n",
        "        \"Use 'Spanish Agent' if it's Spanish, and 'French Agent' if it's French.\"\n",
        "    ),\n",
        "    model=LitellmModel(model=Model, api_key=api_key),\n",
        "    tools=[\n",
        "        detect_language_agent.as_tool(\n",
        "            tool_name=\"detect_language\",\n",
        "            tool_description=\"Detect the language of the user's input\",\n",
        "        ),\n",
        "        spanish_agent.as_tool(\n",
        "            tool_name=\"translate_to_spanish\",\n",
        "            tool_description=\"Translate message to Spanish\",\n",
        "        ),\n",
        "        french_agent.as_tool(\n",
        "            tool_name=\"translate_to_french\",\n",
        "            tool_description=\"Translate message to French\",\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "# --- Main Runner ---\n",
        "async def main():\n",
        "    input_text = \"Say 'Hello, how are you?' in Spanish.\"  # 🔁 You can change input here\n",
        "    result = await Runner.run(orchestrator_agent, input=input_text)\n",
        "    print(\"✅ Final Output:\", result.final_output)\n",
        "\n",
        "# Run the async loop\n",
        "asyncio.run(main())"
      ]
    }
  ]
}